---
title: The tomato experience
knitr:
  opts_chunk: 
    echo: false
    message: false
    warning: false
    comment: NA
    cache: false
    fig.width: 7
    fig.asp: 0.5
    fig.path: "figures_tomatoes/"
    dpi: 320
    out.width: 100%
    
    external: false
    res: 320
    results: "hide"
    split: false 
    tidy: false
    dev: svg
editor_options: 
  chunk_output_type: console
format: 
  html: 
    embed-resources: true
---


```{r setup}
library(httr)
library(apastats)
library(circhelp)
library(data.table)
library(jsonlite)
library(stringr)
library(knitr)
library(Hmisc)
library(ez)
library(superb)

default_font = 'Gill Sans Nova Light'

default_font_size <- 10
default_line_size <- 1/.pt/3.82*4 
default_font_size_mm <- default_font_size/ggplot2:::.pt

default_point_size <- 4*default_line_size

update_geom_defaults("line", list(linewidth = default_line_size))
update_geom_defaults("text", list(size = default_font_size_mm, family = default_font))
update_geom_defaults("segment", list(linewidth = default_line_size))
update_geom_defaults("pointrange", list(linewidth = default_line_size))
update_geom_defaults("vline", list(linewidth = default_line_size, colour = '#AFABAB'))
update_geom_defaults("hline", list(linewidth = default_line_size, colour = '#AFABAB'))
update_geom_defaults('function', list(linewidth = default_line_size))

default_theme<-theme_light(base_size = default_font_size, base_line_size = default_line_size, base_family = default_font)+theme(
  axis.line=element_line(linewidth = I(0.5)), 
  axis.ticks= element_line(linewidth = I(0.25), colour = 'gray'),
  axis.line.x=element_line(),
  axis.line.y=element_line(),
  panel.grid.major = element_blank(), 
  panel.grid.minor = element_blank(),
  legend.title=element_text(size=rel(1)), 
  strip.text=element_text(size=rel(1), colour = 'black'), 
  axis.text=element_text(size=rel(0.9), colour = '#4e4e4e'), 
  axis.title=element_text(size=rel(1), colour = '#4e4e4e'), 
  panel.border= element_blank(),
  strip.background = element_blank(),
  legend.position	='right', 
  legend.key.height = unit(0.7, 'lines'),
  plot.title=element_text(size=rel(1), hjust = 0.5),
  plot.tag.position = c(0,1),
  plot.background = element_blank(),
  text=element_text(size=default_font_size), 
  legend.text=element_text(size=rel(1)), 
  axis.line.x.bottom = element_blank(), 
  axis.line.y.left = element_blank(),
  axis.line.x.top = element_blank(),
  axis.line.y.right = element_blank())
theme_set(default_theme)

default_colors <-c('#3498db','#009f06','#FF7F00', '#7A378B','#f72034')
scale_colour_discrete <- function(...) scale_colour_manual(values=default_colors, ...)
scale_fill_discrete <- function(...) scale_fill_manual(values=default_colors, ...)
scale_shape_discrete <- function(...) scale_shape_manual(values = c(16,21,17, 22), ...)

```

```{r}

headers = c(
  `Authorization` = sprintf("Bearer %s",Sys.getenv('JATOS_TOKEN')),
  `Content-Type` = 'text/plain'
)

jatos_url <- 'https://jatos.mindprobe.eu/jatos/api/v1/'
res <- httr::GET(url = paste0(jatos_url, "admin/token"), httr::add_headers(.headers=headers))

randstring <- function(n = 5000) {
  a <- do.call(paste0, replicate(5, sample(LETTERS, n, TRUE), FALSE))
  paste0(a, sprintf("%04d", sample(9999, n, TRUE)), sample(LETTERS, n, TRUE))
}


temp_dir <- tempdir(check = T)
temp_dir <- gsub('\\\\', '/', temp_dir)
temp_dir <- paste(temp_dir, randstring(1), sep = '/')
res_file <- paste0(tempfile(),'.zip')

study_uid <- Sys.getenv('JATOS_TOMATO_STUDY_UID')

req_url <-  sprintf("%sresults/metadata?studyUuid=%s", jatos_url, study_uid)
system(sprintf('curl  -H "Authorization: %s" %s --output "%s" ', headers[['Authorization']], req_url, res_file))

metadata <- jsonlite::fromJSON(res_file)$data$studyResults[[1]]
setDT(metadata)
unlink(paste0(temp_dir, "/*"))
finished_study <- metadata[studyState=='FINISHED',c('id','startDate','endDate','duration')]

  url <-  sprintf("%sresults?studyUuid=%s", jatos_url, study_uid)
  system(sprintf('curl -i -H "Authorization: %s" %s --output "%s"', headers[['Authorization']], url, res_file))
  unzip(res_file, exdir=temp_dir)  # unzip your file
  
  metadata <- fromJSON(list.files(temp_dir, '*.json', full.names = T, recursive = T))$data$studyResults[[1]]
  
  finished_study_ids <- metadata[,c('id', "endDate", "startDate")]
  setDT(finished_study_ids)
  finished_study_ids[,id:=as.character(id)]
  finished_study_ids[,endDate:=as.POSIXct(endDate/1000, origin="1970-01-01")]
  finished_study_ids[,startDate:=as.POSIXct(startDate/1000, origin="1970-01-01")]
  
  comp_res_meta <- rbindlist(lapply(1:length(metadata$componentResults), \(x) {
    dt <- as.data.table(metadata$componentResults[[x]])
    dt
  }), fill = T)
  flist <- list.files(temp_dir, '*.txt', full.names = T, recursive = T)
  # flist <- flist[str_extract(flist,'study_result_(\\d+)', group = 1)%in%finished_study_ids$id]
  
  cur_data <- rbindlist(lapply(c(flist), \(x){
    print(x)
    comp_res_id <- str_extract(x, '(?<=comp-result_)\\d{6}')
    data <- read_json(x)
    if (length(data)<40){
      return(data.frame())
    }
    browser_check <-data[sapply(data, \(x) x$trial_type=='browser-check')][[1]]

    setDT(browser_check)
    
    data <- data[sapply(data, \(x) x$trial_type=='psychophysics')]
    data <- rbindlist(data, fill = T)
    if ('score' %nin% colnames(data)){
      return(data.frame())
    }

      km <- kmeans(as.matrix(data[!is.na(click_x),.(click_x,click_y)]), 3, nstart = 50)
      sorted_indices <- order(km$centers[, 1])  # Assuming x-coordinate is in the first column
      sorted_indices[2:3] <- rev(sorted_indices[2:3])
       
      # Reassign cluster labels based on sorted order
      new_clusters <- match(km$cluster, sorted_indices)
      data[!is.na(click_x), cue_n_alt:=new_clusters]
      # data[, cue_pos:=ifelse(cue_n==1, 'left', ifelse(cue_n==2, 'right', 'avg'))]
      
    if ('cue_n' %nin% names(data)){
      data[,cue_n:=cue_n_alt]
    } 
    data[,score:=as.numeric(score)]
    data[!is.na(left_colors), left_sd:=circ_sd_360(as.numeric(str_split(left_colors,',', simplify = T))), by = left_colors]
    data[!is.na(right_colors), right_sd:=circ_sd_360(as.numeric(str_split(right_colors,',', simplify = T))), by = right_colors]
    data[,left_colors:=NULL]
    data[,right_colors:=NULL]
    setnafill(data, type = "locf",cols = c('target_color','distr_color','left_color','right_color','target_sd', 'distr_sd', 'target_x', 'distr_x', 'similarity_bin', 'color_bin','left_sd','right_sd','cue_n'))
    setnafill(data, type = "nocb",cols = c('score'))
    #
    if (browser_check[1, .(trial_type)]=='browser-check'){
      data<-cbind(data,browser_check[,.(width, height, fullscreen)])
    }
    data<-data[trial_type=='psychophysics'&seq_type=='response']
    # data[, error:=angle_diff_360(resp_color, target_color)]
    data[,subject_id:=str_extract(x, 'study_result_(\\d+)', group = 1)]
    data[,result_id:=str_extract(x, 'comp-result_(\\d+)', group = 1)]
    data <- merge(data, finished_study_ids, by.x = 'subject_id', by.y = 'id', all.x = T)
    
    data
    
  }), fill = T)

  

tomatoes <- cur_data
tomatoes[,expName:='color_2, fixed dist.']
setnames(tomatoes,c('target_sd','distr_sd'), c('target_noise','distr_noise'), skip_absent = T)

tomatoes[,c('left_color','right_color','resp_color'):=list(angle_diff_360(left_color, 0 ), angle_diff_360(right_color, 0), angle_diff_360(resp_color, 0))]
tomatoes[, realTargetColor:=angle_diff_360(ifelse(cue_n==3, 
                                   atan2(sin(target_color/180*pi)+sin(distr_color/180*pi),
                                         cos(target_color/180*pi)+cos(distr_color/180*pi))/pi*180,
                                   ifelse(cue_n==1, left_color, right_color)), 0),
         by = .(target_color, distr_color)]
tomatoes[,realErr:=angle_diff_360(resp_color, realTargetColor)]
tomatoes[,abs_err:=abs(error)]
tomatoes[cue_pos!=target_x, c('target_noise','distr_noise'):=.(distr_noise, target_noise)]
tomatoes[cue_pos!=target_x, c('target_color','distr_color'):=.(distr_color, target_color)]
tomatoes[,target_noise:=factor(target_noise, levels = c(5, 20), labels = c('low','high'))]
tomatoes[,target_sample_sd:=ifelse(cue_pos<0, left_sd, right_sd)]
tomatoes[,distr_sample_sd:=ifelse(cue_pos>0, left_sd, right_sd)]
tomatoes[,distr_noise:=factor(distr_noise, levels = c(5, 20), labels = c('low','high'))]
tomatoes[,td_dist:=angle_diff_360(distr_color, target_color)]

tomatoes[,bias_distr:= sign(td_dist)*error]
tomatoes[,distr_color:=angle_diff_360(distr_color,0)]
tomatoes <- unique(tomatoes)
tomatoes[!is.na(error),n_by_subj:=.N, by = subject_id]
tomatoes[!is.na(error),n_by_block:=.N, by = .(result_id, subject_id)]

#tomatoes<-tomatoes[n_by_block>20&n_by_subj>320]
tomatoes[, abs_td_dist:=abs(td_dist)]
tomatoes[,target_color:=angle_diff_360(target_color, 0)]
tomatoes[,similarity_binf:=factor(similarity_bin)]
tomatoes[,noise:=interaction(target_noise, distr_noise, sep = ' - ')]
tomatoes<-tomatoes[n_by_subj>300&block>0]

aggr_stats <- tomatoes[,.(totalN = .N, non_missing=n_by_subj[1], circ_sd = circ_sd_360(error, na.rm = T),n_by_subj[1], missed_responses = sum(is.na(error))), keyby = .(subject_id)]
```

```{r results='hide'}
tomatoes[,.(.N, circ_sd = circ_sd_360(error, na.rm = T), mean_abs_err= mean.nn(abs_err)), keyby = .(startDate, endDate,  subject_id)]
```

```{r eval = T}

#outliers 
tomatoes <- tomatoes[subject_id%nin%tomatoes[,.(.N, circ_sd_360(error, na.rm = T)), by = subject_id][V2>60|N<200, subject_id]]
tomatoes[,task_type:=ifelse(cue_n==3,'averaging','single item')]

tomatoes[,subject:=paste0('S',as.numeric(as.factor(subject_id)))]
tomatoes[,subject:=naturalsort::naturalfactor(subject)]

tomatoes[,.(.N, circ_sd_360(error, na.rm = T)), by = subject_id]
db_res <- lapply(split(tomatoes[!is.na(error),], by = c('subject_id', 'task_type')), \(dt){
  dt[,c('be_c','is_outlier','rc_pred','rc_group','shifted_td_dist'):=remove_cardinal_biases(error, realTargetColor, space = '360', plots = 'hide')[,c('be_c','is_outlier','pred','which_bin','shifted_x')], by = .(subject_id, task_type)]
  dt
})

tomatoes <-rbindlist(db_res)
tomatoes <- tomatoes[!is.na(abs_err)&is_outlier==F]
```

```{r}
tomatoes[is_outlier==F&abs_err>90, is_outlier:=T]
# tomatoes[,.(.N, circ_sd = circ_sd_360(error, na.rm = T),circ_sd_correct = circ_sd_360(be_c, na.rm = T), n_by_subj=n_by_subj[1], n_nonmissing=sum(!is.na(error)), share_outliers= mean.nn(is_outlier), mean_abs_err= mean.nn(abs_err)), keyby = .(subject_id,task_type)][,mean.nn(share_outliers), by = task_type]

tomatoes[,bias_to_distr_corr:=sign(td_dist)*be_c]
tomatoes[,bias_to_distr_raw:=sign(td_dist)*error]

tomatoes[,abs_be_c:=abs(be_c)]
tomatoes[,avg_abs_err:=mean.nn(abs(be_c)), by = subject_id]
tomatoes[,noise_equal:=factor(distr_noise==target_noise, levels = c(F, T), labels = c('Unequal noise', 'Equal noise'))]
tomatoes[,bias_distr:=NULL]
tomatoes[,similarity_binf:=factor(similarity_bin)]

tomatoes <- drop.empty.cols(tomatoes)
tomatoes[,c('startDate','endDate','result_id','subject_id','avg_frame_time'):=NULL]

tomatoes <- tomatoes[, lapply(.SD, function(col) if (!all(na.omit(col == col[1]))) col else NULL)]

tomatoes_out <- tomatoes[order(subject, trial_number),.(subject, trial_number, target_color, distr_color, left_color, right_color, left_sd,  right_sd, target_noise, distr_noise, noise, similarity_bin, resp_color,  rawError = error, realTargetColor, realErr, errorCorrected = be_c, is_outlier     )]
fwrite(tomatoes_out, file = 'tomatoes.csv')
```

# Instructions

Read the report below and use it as a basis for your presentation. You can also download the preprocessed data from `tomatoes.csv` and use your favorite software (JASP, jamovi, R, SPSS) to analyze it to get more insight into the study results. The data file has the following columns:

* `subject` - participant identifier (ordinal factor with 34 levels)
* `trial_number` - trial number within the experiment
* `target_color` - the color value of the target stimulus in degrees
* `distr_color` - the color value of the distractor stimulus in degrees
* `left_color` - the color value of the left stimulus in degrees
* `right_color` - the color value of the right stimulus in degrees
* `left_sd` - standard deviation of the color distribution for the left stimulus
* `right_sd` - standard deviation of the color distribution for the right stimulus
* `target_noise` - noise level of the target stimulus (factor: "low" or "high")
* `distr_noise` - noise level of the distractor stimulus (factor: "low" or "high")
* `noise` - combined noise condition from target and distractor (factor with 4 levels: "low - low", "high - low", "low - high", "high - high")
* `similarity_bin` - angular distance between target and distractor colors in degrees (20°, 45°, or 135°)
* `resp_color` - the color value reported by the participant in degrees
* `rawError` - raw error in the participant's response
* `realTargetColor` - the actual target color value to be reported
* `realErr` - the actual error in the participant's response
* `errorCorrected` - the error after correction for individual biases (better to use this one for analyses than the raw error)
* `is_outlier` - binary indicator of whether the trial was identified as an outlier based on the error magnitude (0 = not an outlier, 1 = outlier)

Note that in case of the averaging task what is target and what is distractor is determined randomly as people report the average color of the two items. This is why they are referred to as A and B in @fig-bias-analysis. 

# Methods

## Participants
`r str_to_sentence(apastats:::numbers2words(aggr_stats[,.N]))` participants took part in the study. `r str_to_sentence(apastats:::numbers2words(aggr_stats[,.N]-tomatoes[,lengthu(subject)]))` participants were excluded because of very poor performance (an average absolute error was above the predefined threshold of 60 deg.).

## Apparatus, Stimuli, and Procedure
The experiment was conducted using a web-based platform built with jsPsych (version 7.3.2). Stimuli were presented on participants' personal displays with a minimum required resolution of 1000 × 600 pixels, verified via browser-check.

Participants performed a color estimation task framed as quality control at a "magical tomato factory." On each trial, participants first viewed a central fixation circle (radius = 20 pixels) for 1000 ms. Subsequently, two 8 × 8 color patch stimuli (64 patches per stimulus) appeared simultaneously on the left and right sides of the screen for 1500 ms. Each stimulus measured 256 × 256 pixels, with individual patches sized at 32 × 32 pixels. Each stimulus contained patches with colors sampled from a normal distribution with a specified mean and standard deviation (either 5° or 20° in OKLCH color space). All colors were presented at a constant luminance (L = 50%) and chroma (C = 0.1), with only the hue parameter varying according to the experimental conditions. These color patches represented samples from two tomatoes.

The mean hue of the target was selected randomly to ensure coverage across the full 360° color space. The mean hue of the distractor was determined by the similarity bin factor, with the distractor mean set at either 20°, 45°, or 135° (±3°) away from the target mean, with the direction (clockwise or counterclockwise) determined randomly.

After a 500 ms memory delay, a response cue appeared for 500 ms, indicating which color the participant should report: the left tomato, right tomato, or the average color of both tomatoes. A color wheel (radius = 120 pixels, thickness = 20% of radius) then appeared around the corresponding tomato image(s). Participants selected a color by clicking on the wheel, with response time limited to 10 seconds per trial.

In the training phase (10 trials), participants received extended feedback showing both their selected color and the correct target color. Stimulus presentation times gradually decreased during training. In the test phase, only a numerical score indicated performance accuracy without revealing the correct color.

The experiment had a within-subjects factorial design with the following factors: target position (2 levels: left or right), target standard deviation (2 levels: 5° or 20°), distractor standard deviation (2 levels: 5° or 20°), similarity between target and distractor colors (3 levels: 20°, 45°, or 135°), and task type (2 levels: averaging task or single-item report task). The relative frequency distribution was structured such that participants performed the averaging task (reporting the average color of both stimuli) in 60% of trials and the single-item report task (reporting the color of either the right or left stimulus) in the remaining 40% of trials. For the single-item report task, the target was equally likely to appear on the left or right side. This distribution ensured greater emphasis on the averaging task compared to the single-item report task. The full factorial design with this distribution generated 360 unique experimental conditions, all of which were administered to each participant in the test phase. A mandatory rest period was provided at the midpoint of the experiment (after 50% of trials were completed) to mitigate potential fatigue effects.

# Results


```{r}
#| fig-cap: "Mean absolute error in color reporting as a function of similarity bin and task type. Error bars represent within-subject 95% confidence intervals."
#| label: fig-color-error

# Create the plot with proper axis labels
plot.pointrange(tomatoes[!is.na(abs_err)&is_outlier==F],
                aes(x = similarity_bin, y = abs_be_c, color = task_type), 
                within_subj = TRUE, 
                wid = 'subject', 
                withinvars = c('task_type','similarity_bin')
                ) +
  labs(x = "Similarity Bin (degrees)", 
       y = "Absolute Error (degrees)",
       color = "Task Type") 

# Run ANOVA
abs_error_anova <- ezANOVA(
  data = tomatoes[!is.na(abs_err)&is_outlier==F],
  dv = .(abs_be_c),
  wid = .(subject),
  within = .(task_type, similarity_binf),
  detailed = TRUE,
  type = 3
)



```

The repeated-measures ANOVA revealed an effect of the task type `r describe.ezanova(abs_error_anova, "task_type")` with participants performing better in the single-item report task compared to the averaging task. We also found an effect of the similarity bin `r describe.ezanova(abs_error_anova, "similarity_binf")`, indicating that participants' performance was affected by the similarity between target and distractor colors. The interaction effect was not significant, `r describe.ezanova(abs_error_anova, "task_type:similarity_bin")`.


```{r}
#| fig-cap: "Bias in reported color in the averaging task as a function of similarity bin and noise level. Positive values indicate bias toward a stimulus A in a pair of stimuli A-B with noise levels shown as color. Because the average color is between A and B, bias towards A simultaneously indicates bias away from B and vice versa. Error bars represent within-subject 95% confidence intervals."
#| label: fig-bias-analysis

# Calculate bias relative to target for averaging task
tomatoes[!is.na(abs_err) & task_type=='averaging', 
         bias_rel_to_target := sign(angle_diff_360(target_color, realTargetColor)) * be_c]

# Create the plot
plot.pointrange(tomatoes[is_outlier==F & !is.na(abs_err) & task_type=='averaging',], 
                aes(x = similarity_bin, color = noise, y = bias_rel_to_target), 
                within_subj = TRUE, 
                wid = 'subject', 
                design = 'w') +
  geom_hline(yintercept = 0, linetype = 2)+
  labs(x = "Similarity Bin (degrees)", 
       y = "Bias Relative to A (degrees)",
       color = "Noise Level\n(Stim. A - Stim. B)")

# Run ANOVA on bias
bias_anova <- ezANOVA(
  data = tomatoes[is_outlier==F & !is.na(abs_err) & task_type=='averaging',],
  dv = .(bias_rel_to_target),
  wid = .(subject),
  within = .(similarity_bin, noise),
  type = 3
)
```

For the averaging task, we calculated a bias measure to determine whether participants' color reports were systematically pulled toward one of the original stimuli. This bias was computed by taking the signed error between the reported color and the target color, with the sign indicating whether errors tended toward the distractor (positive values) or away from it (negative values).

The analysis of bias in the averaging task revealed that the effect of similarity bin was not significant, `r describe.ezanova(bias_anova, "similarity_bin")`, indicating that the similarity between the two colors alone did not systematically affect the direction of participants' errors. However, the effect of noise was significant, `r describe.ezanova(bias_anova, "noise")`, demonstrating that the variability in the color patches significantly influenced how participants weighted the stimuli when computing the average. Importantly, we found a significant interaction between similarity bin and noise, `r describe.ezanova(bias_anova, "similarity_bin:noise")`, indicating that the effect of noise on bias was moderated by the similarity between target and distractor colors. This interaction suggests that depending on the noise level, participants weighted the two stimuli differently when computing the average, with higher noise conditions potentially leading to more bias toward the more variable stimuli. 

```{r}

#| label: explore-interaction

# Compute mean and CI for each group
mean_bias <- get_superb_ci(
  tomatoes[!is.na(abs_err) & is_outlier==F & task_type=='averaging'],   
  wid = c('subject'),  
  within = c('noise', 'similarity_binf'), 
  value_var = 'bias_rel_to_target'
)
setDT(mean_bias)

# Add formatted string representation for mean and CI to each row
mean_bias[, mean_ci_str := sprintf("_M_ = %.2f [%.2f, %.2f]", 
                                  center, 
                                  center + lowerwidth, 
                                  center + upperwidth)]

# Split by similarity bin and perform separate ANOVAs
similarity_bins <- unique(tomatoes$similarity_binf)
split_results <- lapply(split(tomatoes[!is.na(abs_err) & is_outlier==F & task_type=='averaging' ], by = 'similarity_bin'), function(dt) {
  
  
  ezANOVA(
    data = dt,
    dv = .(bias_rel_to_target),
    wid = .(subject),
    within = .(noise),
    type = 3
  )
})
names(split_results)<-paste0('c',names(split_results))
```

Separate ANOVAs for each similarity bin showed that the effect of the noise was significant only when items were relatively similar (`r describe.ezanova(split_results$c20)` for 20 deg. similarity and `r describe.ezanova(split_results$c45)` for 45 deg.) but not when they were very different (`r describe.ezanova(split_results$c135)`). With both 20 and 40 similarity, responses were closer to the more variable item, as @fig-bias-analysis shows.

