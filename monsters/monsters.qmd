---
title: Monsters from the outer space
knitr:
  opts_chunk: 
    echo: false
    message: false
    warning: false
    comment: NA
    cache: false
    fig.width: 7
    fig.asp: 0.5
    out.width: 100%
    fig.path: "figures/"
    dpi: 320
    external: false
    res: 320
    results: "hide"
    split: false 
    tidy: false
    dev: svg
editor_options: 
  chunk_output_type: console
format: 
  html: 
    embed-resources: true
---


```{r setup}
library(httr)
library(apastats)
library(data.table)
library(jsonlite)
library(stringr)
library(knitr)
library(Hmisc)
library(superb)

default_font = 'Gill Sans Nova Light'

default_font_size <- 10
default_line_size <- 1/.pt/3.82*4 
default_font_size_mm <- default_font_size/ggplot2:::.pt

default_point_size <- 4*default_line_size

update_geom_defaults("line", list(linewidth = default_line_size))
update_geom_defaults("text", list(size = default_font_size_mm, family = default_font))
update_geom_defaults("segment", list(linewidth = default_line_size))
update_geom_defaults("pointrange", list(linewidth = default_line_size))
update_geom_defaults("vline", list(linewidth = default_line_size, colour = '#AFABAB'))
update_geom_defaults("hline", list(linewidth = default_line_size, colour = '#AFABAB'))
update_geom_defaults('function', list(linewidth = default_line_size))

default_theme<-theme_light(base_size = default_font_size, base_line_size = default_line_size, base_family = default_font)+theme(
  axis.line=element_line(linewidth = I(0.5)), 
  axis.ticks= element_line(linewidth = I(0.25), colour = 'gray'),
  axis.line.x=element_line(),
  axis.line.y=element_line(),
  panel.grid.major = element_blank(), 
  panel.grid.minor = element_blank(),
  legend.title=element_text(size=rel(1)), 
  strip.text=element_text(size=rel(1), colour = 'black'), 
  axis.text=element_text(size=rel(0.9), colour = '#4e4e4e'), 
  axis.title=element_text(size=rel(1), colour = '#4e4e4e'), 
  panel.border= element_blank(),
  strip.background = element_blank(),
  legend.position	='right', 
  legend.key.height = unit(0.7, 'lines'),
  plot.title=element_text(size=rel(1), hjust = 0.5),
  plot.tag.position = c(0,1),
  plot.background = element_blank(),
  text=element_text(size=default_font_size), 
  legend.text=element_text(size=rel(1)), 
  axis.line.x.bottom = element_blank(), 
  axis.line.y.left = element_blank(),
  axis.line.x.top = element_blank(),
  axis.line.y.right = element_blank())
theme_set(default_theme)

default_colors <-c('#3498db','#009f06','#FF7F00', '#7A378B','#f72034')
scale_colour_discrete <- function(...) scale_colour_manual(values=default_colors, ...)
scale_fill_discrete <- function(...) scale_fill_manual(values=default_colors, ...)
scale_shape_discrete <- function(...) scale_shape_manual(values = c(16,21,17, 22), ...)

headers = c(
  `Authorization` = sprintf("Bearer %s", Sys.getenv("JATOS_TOKEN"))
)

jatos_url <- 'https://jatos.mindprobe.eu/jatos/api/v1/'

randstring <- function(n = 5000) {
  a <- do.call(paste0, replicate(5, sample(LETTERS, n, TRUE), FALSE))
  paste0(a, sprintf("%04d", sample(9999, n, TRUE)), sample(LETTERS, n, TRUE))
}

data_list <- list()
study_uid <- Sys.getenv('JATOS_MONSTERS_STUDY_UID')

temp_dir <- tempdir(check = T)
temp_dir <- gsub('\\\\', '/', temp_dir)
temp_dir <- paste(temp_dir, randstring(1), sep = '/')
res_file <- paste0(tempfile(),'.zip')

req_url <-  sprintf("%sresults/metadata?studyUuid=%s", jatos_url, study_uid)
system(sprintf('curl  -H "Authorization: %s" %s --output "%s" ', headers[['Authorization']], req_url, res_file))

metadata <- jsonlite::fromJSON(res_file)$data$studyResults[[1]]
setDT(metadata)
unlink(paste0(temp_dir, "/*"))
finished_study <- metadata[studyState=='FINISHED',c('id','startDate','endDate','duration')]
finished_study[,endDate:=as.POSIXct(endDate/1000, origin="1970-01-01")]
finished_study[,startDate:=as.POSIXct(startDate/1000, origin="1970-01-01")]
finished_study <- finished_study[id!='808752'] # too short duration
url <-  sprintf("%sresults?studyUuid=%s", jatos_url, study_uid)
system(sprintf('curl -i -H "Authorization: %s" %s --output "%s"', headers[['Authorization']], url, res_file))
unzip(res_file, exdir=temp_dir)  # unzip your file

metadata <- jsonlite::fromJSON(list.files(temp_dir, '*.json', full.names = T, recursive = T))$data$studyResults[[1]]

finished_study_ids <- metadata[,c('id', "endDate", "startDate")]
setDT(finished_study_ids)
finished_study_ids[,id:=as.character(id)]
finished_study_ids[,endDate:=as.POSIXct(endDate/1000, origin="1970-01-01")]
finished_study_ids[,startDate:=as.POSIXct(startDate/1000, origin="1970-01-01")]
finished_study_ids <- finished_study_ids[startDate>Sys.getenv("JATOS_START_DATE")]

comp_res_meta <- rbindlist(lapply(1:length(metadata$componentResults), \(x) {
  dt <- as.data.table(metadata$componentResults[[x]])
  dt
}), fill = T)

flist <- list.files(temp_dir, '*.txt', full.names = T, recursive = T)
flist <- flist[str_extract(flist,'study_result_(\\d+)', group = 1)%in%finished_study_ids$id]

data <- suppressWarnings(rbindlist(lapply(c(flist), \(x){
  
  comp_res_id <- str_extract(x, '(?<=comp-result_)\\d{6}')
  data <- read_json(x)
  if (length(data)<10){
    print(x)
    return(data.frame())
  }
  data <- data[sapply(data, \(x) x$trial_type=='psychophysics')]
  
  data <- lapply(data, \(ct){
    ct$monsters <- NULL
    ct
  })
  data <- rbindlist(data, fill = T)

  data[,subject_id:=str_extract(x, 'study_result_(\\d+)', group = 1)]
  data[,result_id:=str_extract(x, 'comp-result_(\\d+)', group = 1)]
  data <- merge(data, finished_study_ids, by.x = 'subject_id', by.y = 'id')
  
  data
  
}), fill = T))

unlink(paste0(temp_dir, "/*"))

data[,participant:=as.numeric(factor(subject_id, levels = sample(unique(data$subject_id)), labels = 1:length(unique(data$subject_id))))]
data[,c('startDate','endDate','result_id','subject_id','avg_frame_time'):=NULL]
data <- drop.empty.cols(data)
data <- data[, lapply(.SD, function(col) if (!all(na.omit(col == col[!is.na(col)][1]))) col else NULL)]

data[,expected_lengthf:=factor(expected_length )]
data[,trial_i_within_blockf:=factor(trial_i_within_block )]
data[,trial_i_within_block_rel:=trial_i_within_block-expected_length]
data[,prevLengthDiff := shift(lengthDiff), by = participant]
data <- data[participant%nin% data[,.(mean.nn(correct), mean.nn(rt)), by = participant][V1<.9, participant]]
data[,log_rt:=log(rt)]

fwrite(data[,.(participant, block_i, expected_length, real_length, lengthDiff, trial_i_within_block, next_wave_in, targetMeanColor, distractorMeanColor, clicked_monster_id, correct, rt)], file = 'monsters.csv')
```

# Instructions

Read the report below and use it as a basis for your presentation. You can also download the preprocessed data from `tomatoes.csv` and use your favorite software (JASP, jamovi, R, SPSS) to analyze it to get more insight into the study results. The data file has the following columns:

- `participant`: Participant identifier.
- `block_i`: Block number within the experiment (indicating progression through sequences).
- `expected_length`: The expected length of the current sequence (5, 6, or 7 trials).
- `real_length`: The actual length of the sequence after applying the length difference (1-12 trials).
- `lengthDiff`: The difference between expected and actual sequence length (-4 to +4 trials).
- `trial_i_within_block`: Position of the current trial within its sequence (1 to real_length).
- `next_wave_in`: Counter shown to participants indicating expected remaining trials before next sequence (0 when a new sequence is about to begin).
- `targetMeanColor`: Hue value (0-360°) of the target "leader" monster.
- `distractorMeanColor`: Hue value (0-360°) of the distractor monsters.
- `clicked_monster_id`: Index of the monster clicked by the participant (0 indicates the leader).
- `correct`: Binary indicator of response accuracy (1 = correct, 0 = incorrect).
- `rt`: Response time in milliseconds.

{{< include monsters_methods.md >}}

## Participants
`r str_to_sentence(apastats:::numbers2words(finished_study[,.N]))` participants took part in the study. `r str_to_sentence(apastats:::numbers2words(finished_study[,.N]-data[,lengthu(participant)]))` participant was excluded because they had zero correct responses. Participation required a web browser with a minimum screen resolution of 1000 × 600 pixels. Demographic information was not collected.

## Results

```{r}
data_descr <- data[,.(.N, mean_RT = mean.nn(rt[correct==1]), mean_corr = mean.nn(correct)), keyby = .( participant)]
```

### Descriptive statistics

Participants were almost always accurate (`r describe.mean.conf(data_descr$mean_corr)`; here and later 95% confidence intervals are given in parentheses) and took on average `r describe.mean.conf(data_descr$mean_RT)` ms to respond.

```{r}
#| label: fig-trial-position
#| fig-cap: "Response time as a function of trial position within sequence for different expected sequence lengths. Error bars represent 95% confidence intervals."

plot.pointrange(data[correct==1], aes(x = trial_i_within_blockf, y = rt, color = expected_lengthf), 
                wid = 'participant', within_subj = F, 
                withinvars=c('trial_i_within_blockf','expected_lengthf'), 
                do_aggregate = T, connecting_line = T) +
  labs(x = "Position in sequence", y = "Response time (ms)", 
       color = "Expected length")

t_res <- rbindlist(lapply(1:8, \(trial_i){
  data.table(t(unclass(dcast(data[correct==1&trial_i_within_block>(trial_i-1)], participant ~ trial_i_within_block==trial_i , value.var = 'rt', fun = mean)[,t.test(`FALSE`,`TRUE`, paired = T)])))
}))
t_test_1_vs_rest <- dcast(data[correct==1], participant ~ trial_i_within_block==1 , value.var = 'rt', fun = mean)[,t.test(`TRUE`,`FALSE`, paired = T)]
```

We first confirmed a general 'priming of pop-out' effect. By comparing response time (RT) on each trial with the average of subsequent trials, we found significantly longer RT (`r describe.ttest(t_res[1])`) for the first trial in each sequence ('wave'). This indicates that participants needed more time to respond when a new sequence began. However, following the first trial, no significant differences were observed between any position and subsequent positions (all _p_ > `r round.p(min(t_res[2:8, unlist(p.value)]), include.rel=F)`). This suggests that performance quickly stabilized after the initial trial in each sequence.

```{r}
#| label: fig-bef_aft_exp_end
#| fig-cap: "Response times relative to baseline (at expected sequence end) for trials before and after the expected end point in sequences that continued longer than expected. Error bars represent 95% confidence intervals."

data[correct==1&trial_i_within_block_rel==0, ref_rt := rt]
data[,rel_rt:=rt-ref_rt[!is.na(ref_rt)], by = .(participant, block_i)]

data_exp <- data[correct==1&trial_i_within_block_rel%between%c(-2,2)&lengthDiff!=0&trial_i_within_block_rel!=0]

plot.pointrange(data_exp, aes(x = trial_i_within_block_rel, y = rel_rt), 
                wid = 'participant', within_subj = T, 
                withinvars=c('trial_i_within_block_rel'), 
                do_aggregate = F, connecting_line = T, x_as_numeric = T) +
  labs(x = 'Trial position relative to expected end of sequence', 
       y = 'RT relative to baseline (ms)') +
  geom_hline(yintercept = 0, linetype = 2) +
  scale_x_continuous(breaks = c(-3:-1,1:3))

t_res1 <- rbindlist(lapply(1:2, \(trial_i){
  res <- dcast(data_exp[abs(trial_i_within_block_rel)==trial_i], participant ~ trial_i_within_block_rel>0 , value.var = 'rel_rt', fun = mean.nn)[,t.test(`FALSE`,`TRUE`, paired = T)]
  res_dt <- data.table(t(unclass(res)))
  res_dt[,descr:= describe.ttest(res)]
  res_dt
}))
t_res2 <- rbindlist(lapply(c(-2,-1,1,2), \(trial_i){
  data.table(t(unclass(data_exp[(trial_i_within_block_rel)==trial_i,mean.nn(rel_rt), by = participant][,t.test(V1)])))
}))
mean_rt_by_rel_pos <- data_exp[, .(rt= mean.nn(rel_rt)), by = .(participant,trial_i_within_block_rel)]
```

We then tested how participants' expectations affect response times. To this end, we analyzed the trials preceding and following the expected end point in sequences that continued longer than expected. The response time at the expected end point was taken as the baseline (for example, if the sequence was expected to end at the 5th trial, the RT for that trial would be the baseline for comparison for that sequence). We found that RTs were numerically lower than the baseline in trials preceding the expected end point (`r mean_rt_by_rel_pos[trial_i_within_block_rel==-1, describe.mean.conf(rt)]`) and numerically higher following the expected end point (`rmean_rt_by_rel_pos[trial_i_within_block_rel==1, describe.mean.conf(rt)]`). The difference between these trials was significant (`r t_res1[1,descr]`; position ±1 at @fig-bef_aft_exp_end) in contrast to trials further away from the expected end of the sequence (`r t_res1[2,descr]`; position ±2 at @fig-bef_aft_exp_end).

```{r}
#| label: fig-rt_first
#| fig-cap: "Response times on the first trial of a sequence as a function of whether the previous sequence was shorter than, equal to, or longer than expected. Error bars represent 95% confidence intervals."

library(ez)
data[,prev_ld_positive:=factor(ifelse(prevLengthDiff>0,'longer than expected', ifelse(prevLengthDiff==0, 'as expected', 'shorter than expected')), levels = c('shorter than expected', 'as expected','longer than expected'))]

plot.pointrange(data[correct==1&trial_i_within_block==1&!is.na(prev_ld_positive)], 
                aes(x = prev_ld_positive, y = rt), 
                wid = 'participant', within_subj = T, 
                do_aggregate = F, design = 'w', connecting_line = T) +
                labs(x = 'Previous sequence type', y = 'Response time (ms)')

eza_res <- ezANOVA(data[correct==1&trial_i_within_block==1&!is.na(prev_ld_positive)], 
        wid = .(participant),
        within = .(prev_ld_positive),
        dv = .(rt),
        type = 3)
```

Finally, we investigated whether the first trial in each sequence is affected by whether expectations were confirmed or violated in the previous sequence (@fig-rt_first). We compared response times on the first trial when the previous sequence was shorter than expected, as expected, or longer than expected. However, we did not find any significant effect of the previous sequence type (`r describe.ezanova(eza_res, 'prev_ld_positive')`). This suggests that participants' responses to a new sequence were not influenced by their experience with expectation violations in the previous sequence.